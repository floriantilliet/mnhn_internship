{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 17:23:45.156824: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-04 17:23:45.288715: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-04 17:23:45.859353: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/dell3/anaconda3/envs/workenv/lib/\n",
      "2023-04-04 17:23:45.859405: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/dell3/anaconda3/envs/workenv/lib/\n",
      "2023-04-04 17:23:45.859408: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "import os\n",
    "import random as rd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pyBigWig as pbg\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import keras.backend as K\n",
    "import pandas as pd\n",
    "import logomaker as lm\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load all chrs\n",
    "X_2L=np.load('/home/florian/projet/r6.16/seq.npz')['2L']\n",
    "X_2R=np.load('/home/florian/projet/r6.16/seq.npz')['2R']\n",
    "X_3L=np.load('/home/florian/projet/r6.16/seq.npz')['3L']\n",
    "X_3R=np.load('/home/florian/projet/r6.16/seq.npz')['3R']\n",
    "X_4=np.load('/home/florian/projet/r6.16/seq.npz')['4']\n",
    "X_X=np.load('/home/florian/projet/r6.16/seq.npz')['X']\n",
    "X_Y=np.load('/home/florian/projet/r6.16/seq.npz')['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create scATAC values for each chr\n",
    "cut=500\n",
    "Y_2L=np.load('/home/florian/projet/scATACseq_14chr.npz')['2L'][0]\n",
    "Y_2L[Y_2L >= cut] = cut\n",
    "Y_2L=Y_2L/cut\n",
    "\n",
    "Y_2R=np.load('/home/florian/projet/scATACseq_14chr.npz')['2R'][0]\n",
    "Y_2R[Y_2R >= cut] = cut\n",
    "Y_2R=Y_2R/cut\n",
    "\n",
    "Y_3L=np.load('/home/florian/projet/scATACseq_14chr.npz')['3L'][0]\n",
    "Y_3L[Y_3L >= cut] = cut\n",
    "Y_3L=Y_3L/cut\n",
    "\n",
    "Y_3R=np.load('/home/florian/projet/scATACseq_14chr.npz')['3R'][0]\n",
    "Y_3R[Y_3R >= cut] = cut\n",
    "Y_3R=Y_3R/cut\n",
    "\n",
    "Y_4=np.load('/home/florian/projet/scATACseq_14chr.npz')['4'][0]\n",
    "Y_4[Y_4 >= cut] = cut\n",
    "Y_4=Y_4/cut\n",
    "\n",
    "Y_X=np.load('/home/florian/projet/scATACseq_14chr.npz')['X'][0]\n",
    "Y_X[Y_X >= cut] = cut\n",
    "Y_X=Y_X/cut\n",
    "\n",
    "Y_Y=np.load('/home/florian/projet/scATACseq_14chr.npz')['Y'][0]\n",
    "Y_Y[Y_Y >= 80] = 80\n",
    "Y_Y=Y_Y/80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load preds\n",
    "pred2L=np.load('/home/florian/projet/models/preds_new_cut_weightless_501bp.npz')['pred2L']\n",
    "pred2R=np.load('/home/florian/projet/models/preds_new_cut_weightless_501bp.npz')['pred2R']\n",
    "pred3L=np.load('/home/florian/projet/models/preds_new_cut_weightless_501bp.npz')['pred3L']\n",
    "pred3R=np.load('/home/florian/projet/models/preds_new_cut_weightless_501bp.npz')['pred3R']\n",
    "pred4=np.load('/home/florian/projet/models/preds_new_cut_weightless_501bp.npz')['pred4']\n",
    "predX=np.load('/home/florian/projet/models/preds_new_cut_weightless_501bp.npz')['predX']\n",
    "predY=np.load('/home/florian/projet/models/preds_new_cut_weightless_501bp.npz')['predY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model\n",
    "from keras.models import load_model\n",
    "model_name='new_cut_weightless'\n",
    "model2 = load_model('/home/florian/projet/models/'+ model_name +'/'+ model_name+ '.h5', compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_saliency_map(input_seq, model):\n",
    "    # Compute the gradients of the output with respect to the input\n",
    "    input_seq=tf.cast(input_seq,tf.float32)\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(input_seq)\n",
    "        output = model(tf.expand_dims(input_seq,0))\n",
    "    grads = tape.gradient(output, input_seq)\n",
    "    \n",
    "\n",
    "    # Compute the saliency map\n",
    "    saliency_map = grads #tf.multiply(input_seq, grads)\n",
    "\n",
    "    # Sum the saliency map over the channel dimension\n",
    "    saliency_map = tf.reduce_sum(saliency_map, axis=-1)\n",
    "\n",
    "    # # Normalize the saliency map\n",
    "    # saliency_map = tf.math.abs(saliency_map)\n",
    "    # saliency_map /= tf.reduce_max(saliency_map)\n",
    "\n",
    "    # Return the saliency map\n",
    "    return saliency_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_saliency_channels(input_seq, model):\n",
    "    # Compute the gradients of the output with respect to the input\n",
    "    input_seq=tf.cast(input_seq,tf.float32)\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(input_seq)\n",
    "        output = model(tf.expand_dims(input_seq,0))\n",
    "    grads = tape.gradient(output, input_seq)\n",
    "\n",
    "    # Compute the saliency map\n",
    "    saliency_map = grads #tf.multiply(input_seq, grads)\n",
    "\n",
    "    # # Normalize the saliency map\n",
    "    # saliency_map = tf.math.abs(saliency_map)\n",
    "    # saliency_map /= tf.reduce_max(saliency_map)\n",
    "\n",
    "    # Return the saliency map\n",
    "    return saliency_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_pred(input,model):\n",
    "    model=model\n",
    "    return model(tf.expand_dims(tf.cast(input,tf.float32),0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_pred_seq(input,window_start,model):\n",
    "    model=model\n",
    "    X=[]\n",
    "    for i in range(window_start,window_start+2001):\n",
    "        X.append(np.array(fast_pred(input[i-1000:i+1001],model))[0])\n",
    "    return(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max(array,n):\n",
    "    return ((-array).argsort()[:n])\n",
    "\n",
    "def get_min(array,n):\n",
    "    return (array.argsort()[:n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutation(window_start,chr, vals):\n",
    "    mut=np.copy(chr)\n",
    "    for i in vals:\n",
    "        if 0 < i <= 2001:\n",
    "            mut[i+window_start]=np.roll(mut[i+window_start],1)\n",
    "        elif 2001 < i <=4002:\n",
    "            mut[i+window_start-2001]=np.roll(mut[i+window_start-2001],1)\n",
    "        elif 4002 < i <=6003:\n",
    "            mut[i+window_start-4002]=np.roll(mut[i+window_start-4002],1)\n",
    "        else:\n",
    "            mut[i+window_start-6003]=np.roll(mut[i+window_start-6003],1)\n",
    "    return mut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_map(input,window_start,model):\n",
    "    model=model\n",
    "    Y=np.zeros(4002)\n",
    "    for i in range (-1000,1000):\n",
    "        x=np.array(compute_saliency_map(tf.cast(input[window_start+i:window_start+2001+i],tf.float32),model))\n",
    "        y=np.concatenate((np.zeros(1000+i),x,np.zeros(1001-i)))\n",
    "        Y=np.vstack([Y,y])\n",
    "    return(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    vals = x[~x.isnull()].values\n",
    "    vals = np.resize(vals, len(x))\n",
    "    return vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/florian/projet/scATACseq')\n",
    "folder=os.listdir('/home/florian/projet/scATACseq')\n",
    "chr=[\"2L\",\"2R\",\"3L\",\"3R\",\"4\",\"X\",\"Y\"]\n",
    "for j in chr:\n",
    "    my_np1=[]\n",
    "    for cell in folder:\n",
    "        bw=pbg.open(cell)\n",
    "        arr=(bw.values(j,0,-1,numpy=True))\n",
    "        my_np1.append(arr.astype(dtype='float16')[::10])\n",
    "    my_pd=pd.DataFrame(my_np1,dtype='float16').T\n",
    "    my_pd.columns=[i[:-len('.dedup.no_blacklist.RPGCnormalized.bw')] for i in folder]\n",
    "    csv_file = 'signaux{}.csv'.format(j)\n",
    "    with open(csv_file, mode='w') as f:\n",
    "        my_pd.to_csv(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31630f766c371ce3d9f9481e86efb9338468fe692bd18c62142384c30b83e8be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
