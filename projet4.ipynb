{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import os\n",
    "import random as rd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pyBigWig as pbg\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import keras.backend as K\n",
    "import pandas as pd\n",
    "import logomaker as lm\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load all chrs\n",
    "X_2L=np.load('/home/florian/projet/r6.16/seq.npz')['2L']\n",
    "X_2R=np.load('/home/florian/projet/r6.16/seq.npz')['2R']\n",
    "X_3L=np.load('/home/florian/projet/r6.16/seq.npz')['3L']\n",
    "X_3R=np.load('/home/florian/projet/r6.16/seq.npz')['3R']\n",
    "X_4=np.load('/home/florian/projet/r6.16/seq.npz')['4']\n",
    "X_X=np.load('/home/florian/projet/r6.16/seq.npz')['X']\n",
    "X_Y=np.load('/home/florian/projet/r6.16/seq.npz')['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create scATAC values for each chr\n",
    "cut=500\n",
    "Y_2L=np.load('/home/florian/projet/scATACseq_14chr.npz')['2L'][0]\n",
    "Y_2L[Y_2L >= cut] = cut\n",
    "Y_2L=Y_2L/cut\n",
    "\n",
    "Y_2R=np.load('/home/florian/projet/scATACseq_14chr.npz')['2R'][0]\n",
    "Y_2R[Y_2R >= cut] = cut\n",
    "Y_2R=Y_2R/cut\n",
    "\n",
    "Y_3L=np.load('/home/florian/projet/scATACseq_14chr.npz')['3L'][0]\n",
    "Y_3L[Y_3L >= cut] = cut\n",
    "Y_3L=Y_3L/cut\n",
    "\n",
    "Y_3R=np.load('/home/florian/projet/scATACseq_14chr.npz')['3R'][0]\n",
    "Y_3R[Y_3R >= cut] = cut\n",
    "Y_3R=Y_3R/cut\n",
    "\n",
    "Y_4=np.load('/home/florian/projet/scATACseq_14chr.npz')['4'][0]\n",
    "Y_4[Y_4 >= cut] = cut\n",
    "Y_4=Y_4/cut\n",
    "\n",
    "Y_X=np.load('/home/florian/projet/scATACseq_14chr.npz')['X'][0]\n",
    "Y_X[Y_X >= cut] = cut\n",
    "Y_X=Y_X/cut\n",
    "\n",
    "Y_Y=np.load('/home/florian/projet/scATACseq_14chr.npz')['Y'][0]\n",
    "Y_Y[Y_Y >= 80] = 80\n",
    "Y_Y=Y_Y/80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load preds\n",
    "pred2L=np.load('/home/florian/projet/models/preds_new_cut_weightless_501bp.npz')['pred2L']\n",
    "pred2R=np.load('/home/florian/projet/models/preds_new_cut_weightless_501bp.npz')['pred2R']\n",
    "pred3L=np.load('/home/florian/projet/models/preds_new_cut_weightless_501bp.npz')['pred3L']\n",
    "pred3R=np.load('/home/florian/projet/models/preds_new_cut_weightless_501bp.npz')['pred3R']\n",
    "pred4=np.load('/home/florian/projet/models/preds_new_cut_weightless_501bp.npz')['pred4']\n",
    "predX=np.load('/home/florian/projet/models/preds_new_cut_weightless_501bp.npz')['predX']\n",
    "predY=np.load('/home/florian/projet/models/preds_new_cut_weightless_501bp.npz')['predY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model\n",
    "from keras.models import load_model\n",
    "model_name='new_cut_weightless'\n",
    "model2 = load_model('/home/florian/projet/models/'+ model_name +'/'+ model_name+ '.h5', compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_saliency_map(input_seq, model):\n",
    "    # Compute the gradients of the output with respect to the input\n",
    "    input_seq=tf.cast(input_seq,tf.float32)\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(input_seq)\n",
    "        output = model(tf.expand_dims(input_seq,0))\n",
    "    grads = tape.gradient(output, input_seq)\n",
    "    \n",
    "\n",
    "    # Compute the saliency map\n",
    "    saliency_map = grads #tf.multiply(input_seq, grads)\n",
    "\n",
    "    # Sum the saliency map over the channel dimension\n",
    "    saliency_map = tf.reduce_sum(saliency_map, axis=-1)\n",
    "\n",
    "    # # Normalize the saliency map\n",
    "    # saliency_map = tf.math.abs(saliency_map)\n",
    "    # saliency_map /= tf.reduce_max(saliency_map)\n",
    "\n",
    "    # Return the saliency map\n",
    "    return saliency_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_saliency_channels(input_seq, model):\n",
    "    # Compute the gradients of the output with respect to the input\n",
    "    input_seq=tf.cast(input_seq,tf.float32)\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(input_seq)\n",
    "        output = model(tf.expand_dims(input_seq,0))\n",
    "    grads = tape.gradient(output, input_seq)\n",
    "\n",
    "    # Compute the saliency map\n",
    "    saliency_map = grads #tf.multiply(input_seq, grads)\n",
    "\n",
    "    # # Normalize the saliency map\n",
    "    # saliency_map = tf.math.abs(saliency_map)\n",
    "    # saliency_map /= tf.reduce_max(saliency_map)\n",
    "\n",
    "    # Return the saliency map\n",
    "    return saliency_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_pred(input,model):\n",
    "    model=model\n",
    "    return model(tf.expand_dims(tf.cast(input,tf.float32),0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_pred_seq(input,window_start,model):\n",
    "    model=model\n",
    "    X=[]\n",
    "    for i in range(window_start,window_start+2001):\n",
    "        X.append(np.array(fast_pred(input[i-1000:i+1001],model))[0])\n",
    "    return(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max(array,n):\n",
    "    return ((-array).argsort()[:n])\n",
    "\n",
    "def get_min(array,n):\n",
    "    return (array.argsort()[:n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutation(window_start,chr, vals):\n",
    "    mut=np.copy(chr)\n",
    "    for i in vals:\n",
    "        if 0 < i <= 2001:\n",
    "            mut[i+window_start]=np.roll(mut[i+window_start],1)\n",
    "        elif 2001 < i <=4002:\n",
    "            mut[i+window_start-2001]=np.roll(mut[i+window_start-2001],1)\n",
    "        elif 4002 < i <=6003:\n",
    "            mut[i+window_start-4002]=np.roll(mut[i+window_start-4002],1)\n",
    "        else:\n",
    "            mut[i+window_start-6003]=np.roll(mut[i+window_start-6003],1)\n",
    "    return mut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_map(input,window_start,model):\n",
    "    model=model\n",
    "    Y=np.zeros(4002)\n",
    "    for i in range (-1000,1000):\n",
    "        x=np.array(compute_saliency_map(tf.cast(input[window_start+i:window_start+2001+i],tf.float32),model))\n",
    "        y=np.concatenate((np.zeros(1000+i),x,np.zeros(1001-i)))\n",
    "        Y=np.vstack([Y,y])\n",
    "    return(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31630f766c371ce3d9f9481e86efb9338468fe692bd18c62142384c30b83e8be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
